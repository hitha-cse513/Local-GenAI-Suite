
# ğŸ§  Gen AI Suite: All-in-One Local AI Workspace

## Overview

The **Gen AI Suite** is a Flask-based, multi-tool web application that unifies cutting-edge AI models for **conversation, document analysis, code generation, and image creation** â€” all running locally on your system.

It integrates the power of **Ollama LLaMA 2**, **LangChain**, **Stable Diffusion**, and **Hugging Face Transformers** into one intuitive interface, perfect for researchers, developers, and AI enthusiasts.

ğŸŒ **Local App URL:**
[http://127.0.0.1:5000](http://127.0.0.1:5000)

---

## Source

* **LLaMA 2 (Ollama)** â€” for natural language conversations and reasoning.
* **LangChain + FAISS** â€” for PDF question answering with vector-based retrieval.
* **Hugging Face Transformers** â€” for on-demand Python code generation.
* **Stable Diffusion 2.1** â€” for AI image synthesis powered by diffusion models.
* **Flask** â€” provides a clean and dynamic web interface.

---

## Features

* ğŸ’¬ **LLaMA 2 Chatbot** â€” Chat naturally with a local AI assistant.
* ğŸ“„ **PDF Q&A Assistant** â€” Upload a PDF and ask context-aware questions.
* ğŸ’» **Python Code Generator** â€” Generate ready-to-use Python scripts from natural language prompts.
* ğŸ–¼ï¸ **Image Generator** â€” Create AI-generated artwork and visuals using Stable Diffusion.
* ğŸ¨ **Unified Modern Interface** â€” Beautiful, glassmorphic design with gradient blue aesthetics.
* âš™ï¸ **Runs Entirely Offline** â€” All models run locally; no API keys or cloud usage required.

---

## Key Modules

### 1. ğŸ—¨ï¸ LLaMA 2 Chatbot

* Built with **Ollama LLaMA 2** for local inference.
* Engages in conversational dialogue and reasoning.
* Simple, responsive chat UI with message bubbles.

### 2. ğŸ“š PDF Q&A Assistant

* Uses **LangChainâ€™s RetrievalQA** pipeline.
* Extracts and embeds PDF text using **OllamaEmbeddings** + **FAISS**.
* Accurately retrieves relevant paragraphs for user queries.

### 3. ğŸ’» Python Code Generator

* Powered by **Hugging Face Transformers** and the model `GuillenLuis03/PyCodeGPT`.
* Converts plain English prompts into executable Python code.

### 4. ğŸ–¼ï¸ Image Generator

* Uses **Stable Diffusion 2.1** via Hugging Face **Diffusers**.
* Generates beautiful, high-resolution images from text prompts.
* Saves images to temporary local files and displays them instantly.

---

## Installation & Usage

### ğŸ”§ Clone the Repository

```bash
git clone https://github.com/hitha-cse513/Local-GenAi-Suite.git
cd  Local-GenAi-Suite
```

---

### ğŸ“¦ Install Dependencies

Ensure **Python 3.9+** is installed, then run:

```bash
pip install -r requirements.txt
```

---

### ğŸ§  Set Up Ollama (for LLaMA 2)

Install Ollama (for macOS, Windows, or Linux) from [https://ollama.ai](https://ollama.ai).

Then, pull the **LLaMA 2 model**:

```bash
ollama pull llama2
ollama serve
```

Keep this service running in the background.

```bash
ollama run llama2
```
---

### â–¶ï¸ Run the App

```bash
python app.py
```

Once the server starts, open your browser and go to:

```bash
http://127.0.0.1:5000
```

Explore the following tools:

| Tool                | Description                          | URL         |
| ------------------- | ------------------------------------ | ----------- |
| ğŸ’¬ Chatbot          | Conversational AI powered by LLaMA 2 | `/chatbot`  |
| ğŸ“„ PDF Q&A          | Document-based question answering    | `/pdf_qa`   |
| ğŸ’» Code Generator   | Natural-language â†’ Python code       | `/codegen`  |
| ğŸ–¼ï¸ Image Generator | Stable Diffusion text-to-image       | `/imagegen` |

---

## Screenshots

ğŸ§  **Home Dashboard**
<br><br> <img src="https://github.com/hitha-cse513/Local-GenAI-Suite/blob/main/screenshots/Screenshot 2.png" width="700">

ğŸ’¬ **Chatbot Interface** 
<br><br> <img src="https://github.com/hitha-cse513/Local-GenAI-Suite/blob/main/screenshots/Screenshot 6.png" width="700">

ğŸ“„ **PDF Q&A Assistant**
<br><br> <img src="https://github.com/hitha-cse513/Local-GenAI-Suite/blob/main/screenshots/Screenshot 8.png" width="700">

ğŸ’» **Code Generator** 
<br><br> <img src="https://github.com/hitha-cse513/Local-GenAI-Suite/blob/main/screenshots/Screenshot 9.png" width="700">

---



## Notes

* **GPU Recommended:** Stable Diffusion requires CUDA or Apple MPS for image generation.
* **FAISS** will fall back to CPU if no GPU is available.
* You can easily integrate new tools â€” just create a new `.html` file and add a route in `app.py`.

---

## Credits

* ğŸ§  [Ollama](https://ollama.ai) â€” Local LLM serving framework
* ğŸ”— [LangChain](https://www.langchain.com) â€” Modular AI pipeline framework
* ğŸ¤— [Hugging Face](https://huggingface.co) â€” Transformers & Diffusers
* ğŸ¨ [Stability AI](https://stability.ai) â€” Stable Diffusion model
* âš™ï¸ [Flask](https://flask.palletsprojects.com) â€” Lightweight web framework

---

## License

This project is released under the **MIT License** â€” free for personal and commercial use with attribution.


